{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText\n",
    "\n",
    "Authors:\n",
    "* Aurelien ROUXEL\n",
    "* Ethan MACHAVOINE\n",
    "* Jonathan POELGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets as ds\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/ethan/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Found cached dataset imdb (/home/ethan/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds.load_dataset('imdb', split='train')\n",
    "ds_test = ds.load_dataset('imdb', split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(base_text: str):\n",
    "  \"\"\"\n",
    "  Preprocess the text before classification\n",
    "  Args:\n",
    "    base_text: the string to preprocess\n",
    "  Return:\n",
    "    The preprocessed text\n",
    "  \"\"\"\n",
    "  base_text = base_text.lower()\n",
    "  base_text = base_text.replace(\"<br />\",' ')\n",
    "  text = \"\"\n",
    "  ponct = string.punctuation\n",
    "  for char in base_text:\n",
    "    if char in ponct:\n",
    "      text += ' '\n",
    "    else:\n",
    "      text += char\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_label(label):\n",
    "    if label == 0:\n",
    "        return \"negative\"\n",
    "    return \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [f\"__label__{text_label(text['label'])} {preprocessing(text['text'])}\\n\" for text in ds_train]\n",
    "test_set = [f\"__label__{text_label(text['label'])} {preprocessing(text['text'])}\\n\" for text in ds_test]\n",
    "random.shuffle(train_set)\n",
    "random.shuffle(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"imdb.train\", \"w\") as f:\n",
    "    f.writelines(train_set)\n",
    "with open(\"imdb.test\", \"w\") as f:\n",
    "    f.writelines(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train a FastText classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 6M words\n",
      "Number of words:  75900\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 4538137 lr:  0.000000 avg.loss:  0.381982 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model_first = fasttext.train_supervised(input=\"imdb.train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "* Read 5M words\n",
    "* Number of words:  75900\n",
    "* Number of labels: 2\n",
    "* Progress: 100.0% words/sec/thread: 4541135 lr:  0.000000 avg.loss:  0.388679 ETA:   0h 0m 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_values(model, test_set):\n",
    "    values = 0\n",
    "    for text in test_set:\n",
    "        label = text[:17]\n",
    "        predict = model.predict(text[:-1])[0][0]\n",
    "        if label == predict:\n",
    "            values += 1\n",
    "    return values\n",
    "\n",
    "def compute_accuracy(model, test_set):\n",
    "    tn_fn = get_true_values(model, test_set)\n",
    "    samples, _, _ = model.test(\"imdb.test\")\n",
    "    return tn_fn / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87852\n"
     ]
    }
   ],
   "source": [
    "accuracy = compute_accuracy(model_first, test_set)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "* Accuracy: 0.879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use the hyperparameters search functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, validation_set = train_test_split(train_set, test_size=0.2, random_state=42)\n",
    "random.shuffle(training_set)\n",
    "random.shuffle(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"imdb.training.hyperparameter\", \"w\") as f:\n",
    "    f.writelines(training_set)\n",
    "with open(\"imdb.validation.hyperparameter\", \"w\") as f:\n",
    "    f.writelines(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:    9 Best score:  0.899400 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 4M words\n",
      "Number of words:  69077\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 1574213 lr:  0.000000 avg.loss:  0.045578 ETA:   0h 0m 0s 11.8% words/sec/thread: 1663571 lr:  0.074928 avg.loss:  0.284104 ETA:   0h 0m23s\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(input='imdb.training.hyperparameter'\n",
    "                                  , autotuneValidationFile='imdb.validation.hyperparameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "* Progress: 100.0% Trials:   11 Best score:  0.899000 ETA:   0h 0m 0s\n",
    "* Training again with best arguments\n",
    "* Read 4M words\n",
    "* Number of words:  69077\n",
    "* Number of labels: 2\n",
    "* Progress: 100.0% words/sec/thread: 1881838 lr:  0.000000 avg.loss:  0.043658 ETA:   0h 0m 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89616\n"
     ]
    }
   ],
   "source": [
    "accuracy = compute_accuracy(model, test_set)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "* Accuracy: 0.89588"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Look at the differences between the 2 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(f\"First model attributes:\\n\\t-learning rate: {model_first.lr},\\n\\t-dimension of word vectors: {model_first.dim},\\n\\t-epoch: {model_first.epoch}\\n\")\n",
    "print(f\"Hyperparameters trained model attributes:\\n\\t-learning rate: {model.lr},\\n\\t-dimension of word vectors: {model.dim},\\n\\t-epoch: {model.epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model attributes:\n",
    "* learning rate: 0.1,\n",
    "* dimension of word vectors: 100,\n",
    "* epoch: 5\n",
    "\n",
    "Hyperparameters trained model attributes:\n",
    "* learning rate: 0.08499425639667486,\n",
    "* dimension of word vectors: 92,\n",
    "* epoch: 100\n",
    "\n",
    "#### About the differences, we can say that the model with hyperparameters training was trained for much longer, but with a slightly slower leaning rate and words represented with less features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Two wrongly classified examples from the tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First:\n",
      "\t-text: i just got back from seeing   comedian   it was   alright  it kept me looking at the screen  its just not the type of thing i like to go pay  7 to see   now don t get me wrong  it d make a great hbo feature  if this were something i was watching on tv  i d be hooked right in  it gives an amazing look at what comics go through before and after getting on stage  it will interest anyone who likes watching comics   but when i go to the movies  i like to be entertained  i m not there to be educated  now i know what its like for jerry seinfeld before he goes out on stage    great  but truthfully  i d rather just laugh at his jokes than worry about any of that   one more thing  with the bad attitude onry adams has  i d expect to see him taking my order from burger king before i see his hbo special  he wasn t funny  he s the kind of person that you love to hate , \n",
      "\t-true label: negative,\n",
      "\t-predicted label: positive\n",
      "\n",
      "Second:\n",
      "\t-text: this has to be one of  if not the greatest mob crime films of all time  every thing about this movie is great  the acting in this film is of true quality  master p s acting skills make you actually believe he is italian  the cinematography is excellent too  probably the best ever  this movie was great  and i have the brain capacity of an earth worm , \n",
      "\t-true label: negative,\n",
      "\t-predicted label: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "falses = [(text, model.predict(text[:-1])[0][0]) for text in test_set if model.predict(text[:-1])[0][0] != text[:17]]\n",
    "first = falses[1]\n",
    "second = falses[-1]\n",
    "print(f\"First:\\n\\t-text: {first[0][18:-1]}, \\n\\t-true label: {first[0][9:17]},\\n\\t-predicted label: {first[1][9:17]}\\n\")\n",
    "print(f\"Second:\\n\\t-text: {second[0][18:-1]}, \\n\\t-true label: {second[0][9:17]},\\n\\t-predicted label: {second[1][9:17]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First:\n",
    "* text: i just got back from seeing   comedian   it was   alright  it kept me looking at the screen  its just not the type of thing i like to go pay  7 to see   now don t get me wrong  it d make a great hbo feature  if this were something i was watching on tv  i d be hooked right in  it gives an amazing look at what comics go through before and after getting on stage  it will interest anyone who likes watching comics   but when i go to the movies  i like to be entertained  i m not there to be educated  now i know what its like for jerry seinfeld before he goes out on stage    great  but truthfully  i d rather just laugh at his jokes than worry about any of that   one more thing  with the bad attitude onry adams has  i d expect to see him taking my order from burger king before i see his hbo special  he wasn t funny  he s the kind of person that you love to hate, \n",
    "* true label: negative,\n",
    "* predicted label: positive\n",
    "\n",
    "Second:\n",
    "* text: this has to be one of  if not the greatest mob crime films of all time  every thing about this movie is great  the acting in this film is of true quality  master p s acting skills make you actually believe he is italian  the cinematography is excellent too  probably the best ever  this movie was great  and i have the brain capacity of an earth worm , \n",
    "* true label: negative,\n",
    "* predicted label: positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  For the first one, we can see that the writer actually liked the movie but would have prefered to watch it alone at home than at the cinema,  which made this comment negative, but the model probably didn't catch up with this fact, which led to wrongly classify it. \n",
    "\n",
    "#### For the second, it is actually pretty obvious why it was wrongly classified, and that is because the comment is actually positive until we reach the end and see that the writer was being sarcastic, which probably wasn't recognised by the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
